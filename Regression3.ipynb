{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/eduardojdiniz/CichyWanderers/blob/b49ac01ec04b7d391eef75631c709dfd8661830c/RDMs_loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDMs loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CichyWanderers GitHub Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/eduardojdiniz/CichyWanderers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CichyWanderers.dataloader as dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import AlexNet loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CichyWanderers.alexnet as alexnet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and create Cichy et al, 2014 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, RDM_dict, stim_dict = dataloader.create_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and create AlexNet model (pretrained on ImageNet) RDMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_RDM_dict = alexnet.create_alexnet_RDM_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    \n",
    "<summary><font color='blue'>Click here for details about the dictionaries structure</font>\n",
    "</summary>\n",
    "\n",
    "### Dictionaries structures\n",
    "    \n",
    "#### `RDM_dict`\n",
    "    RDM_dict: dict with keys 'MEG', 'fMRI_EVC', 'fMRI_IT'\n",
    "    'MEG'     : ndarray, (16, 2, 1301, 92, 92)\n",
    "        16 subjects, 2 sessions, 1301 time points (from -100 ms to 1200 ms\n",
    "        wrt to stimulus onset at 0 ms), 92 conditions by 92 conditions.\n",
    "        The last 2 dimensions form representational dissimilarity matrices of\n",
    "        decoding accuracies, symmetric accross the diagonal, with the diagonal\n",
    "        undefined (NaN).\n",
    "    'fMRI_EVC': ndarray, (15, 92, 92)\n",
    "        15 subjects, 92 conditions by 92 conditions.\n",
    "        The last 2 dimensions form a representational dissimilarity matrix of\n",
    "        spearman correlation for the EVC cortex, symmetric accross the diagonal,\n",
    "        with the diagonal undefined (NaN).\n",
    "    'fMRI_IT' : ndarray, (15, 92, 92)\n",
    "        15 subjects, 92 conditions by 92 conditions.\n",
    "        The last 2 dimensions form a representational dissimilarity matrix of\n",
    "        spearman correlation for the IT cortex, symmetric accross the diagonal,\n",
    "        with the diagonal undefined (NaN).\n",
    "        \n",
    "#### `stim_dict`        \n",
    "    stim_dict: dict with keys 'category', 'human', 'face', 'animate', 'natural', 'imagepath'\n",
    "    'category'  : list[str], indicating category\n",
    "    'human'     : list[int], indicating membership (0=not a member, 1=member)\n",
    "    'face'      : list[int], indicating membership (0=not a member, 1=member)\n",
    "    'animate'   : list[int], indicating membership (0=not a member, 1=member)\n",
    "    'natural'   : list[int], indicating membership (0=not a member, 1=member)\n",
    "    'imagepath' : list[str], jpeg image filepath\n",
    "\n",
    "#### `alexnet_RDM_dict`\n",
    "    alexnet_RDM_dict: dict with keys 'layer_1', ..., 'layer_8'\n",
    "    Each item is a ndarray, (92, 92), a representational dissimilarity matrix of\n",
    "    spearman correlation of the layer activation to each pair of visual stimuli\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partialling Out the Representational Dissimilarities based on Low Level Image Statistics \n",
    "\n",
    "Different filters in different layers of Deep Convolutional Neural Networks such as AlexNet are trying to highlight or activate different parts of the image. Some filters are acting as edge, texture, and color detectors, others are detecting a particular region and still others are acting as background detectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average RDMs across subjects and sessions\n",
    "MEG_RDMs = np.mean(RDM_dict['MEG'], axis=(0,1))\n",
    "fMRI_EVC = np.mean(RDM_dict['fMRI_EVC'], axis=0)\n",
    "fMRI_IT = np.mean(RDM_dict['fMRI_IT'], axis=0)\n",
    "layer_1 = alexnet_RDM_dict['layer_1'] \n",
    "layer_2 = alexnet_RDM_dict['layer_2'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(x):\n",
    "    return ((x - x.min()) * (1/(x.max() - x.min()))).astype('float32')\n",
    "\n",
    "def get_residual_RDM(X, y):\n",
    "  \n",
    "  # Indices of lower triangular matrix, excluding the diagonal\n",
    "  n_stim = X.shape[0]\n",
    "  li = np.tril_indices(n_stim, k=-1) \n",
    "  di = np.diag_indices(n_stim)\n",
    "    \n",
    "  X_flat = X[li].reshape((-1,1))\n",
    "  y_flat = y[li].reshape((-1,1)) \n",
    "  #X_rescaled = rescale(X_flat)\n",
    "  #y_rescaled = rescale(y_flat)\n",
    "  X_rescaled = X_flat \n",
    "  y_rescaled = y_flat\n",
    "  reg = LinearRegression().fit(X_rescaled, y_rescaled)\n",
    "  res = y_rescaled - reg.predict(X_rescaled)\n",
    "  # Fill low triangular matrix with residuals\n",
    "  RDM = np.zeros_like(X)\n",
    "  RDM[li] = res.squeeze()\n",
    "   \n",
    "  # Make it symmetrical\n",
    "  RDM = np.tril(RDM) + np.triu(RDM.T, 1)\n",
    "\n",
    "  # Restore original diagonal  \n",
    "  #RDM[di] = X[di]\n",
    "\n",
    "  return RDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total duration of stimulus presentation, in ms\n",
    "T_stim = MEG_RDMs.shape[0]\n",
    "\n",
    "# Number of stimuli\n",
    "n_stim = MEG_RDMs.shape[1]\n",
    "\n",
    "resRDM_dict = {'layer_1': {}, 'layer_2': {}}\n",
    "\n",
    "# Get the residual RDMs for MEG\n",
    "resMEG_RDMs_layer1 = np.zeros_like(MEG_RDMs)\n",
    "resMEG_RDMs_layer2 = np.zeros_like(MEG_RDMs)\n",
    "for t in range(0, T_stim):\n",
    "  # Load MEG RDM at a given timepoint \n",
    "  # +100 as the RDMs provided are from -100ms to 1300ms after the stimulus onset\n",
    "  RDM = MEG_RDMs[t]\n",
    "  resMEG_RDMs_layer1[t] = get_residual_RDM(layer_1, RDM)\n",
    "  resMEG_RDMs_layer2[t] = get_residual_RDM(layer_2, RDM)\n",
    "resRDM_dict['layer_1']['MEG'] = resMEG_RDMs_layer1\n",
    "resRDM_dict['layer_2']['MEG'] = resMEG_RDMs_layer2\n",
    "del RDM, resMEG_RDMs_layer1, resMEG_RDMs_layer2\n",
    "\n",
    "# Get the residual RDMs for fMRI\n",
    "resRDM_dict['layer_1']['fMRI_EVC'] = get_residual_RDM(layer_1, fMRI_EVC)\n",
    "resRDM_dict['layer_2']['fMRI_EVC'] = get_residual_RDM(layer_2, fMRI_EVC)\n",
    "resRDM_dict['layer_1']['fMRI_IT'] = get_residual_RDM(layer_1, fMRI_IT)\n",
    "resRDM_dict['layer_2']['fMRI_IT'] = get_residual_RDM(layer_2, fMRI_IT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RDM_plot import plot_rdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "@widgets.interact( resRDMs=widgets.fixed(resRDM_dict[\"layer_1\"][\"MEG\"]),\n",
    "                   RDMs=widgets.fixed(MEG_RDMs),\n",
    "                   percentile=widgets.Checkbox(value=True, description=\"percentile\"),\n",
    "                   timepoint=widgets.IntSlider(min=0, max=1200, step=10, value=500, description='t (ms):') )\n",
    "def plot_RDMs(resRDMs, RDMs,timepoint=0, percentile=False):\n",
    "    \"\"\"Helper function for visualize MEG RDMs with an interactive \n",
    "    slider for the timepoint.\"\"\"\n",
    "    # Load RDM at a given timepoint \n",
    "    # +100 as the RDMs provided are from -100ms to 1000ms after the stimulus onset\n",
    "    resRDM = np.array(resRDMs[timepoint+100])\n",
    "    RDM = np.array(RDMs[timepoint+100])\n",
    "    title_res = \"Residual MEG RDM at t = \" + str(timepoint) + \" ms\"\n",
    "    title = \"MEG RDM at t = \" + str(timepoint) + \" ms\"\n",
    "    plot_rdm(resRDM, percentile=percentile, title=title_res)\n",
    "    plot_rdm(RDM, percentile=percentile, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fMRI EVC residual RDM\n",
    "title_res = \"Residual fMRI EVC RDM\"\n",
    "title = \"fMRI EVC RDM\"\n",
    "plot_rdm(resRDM_dict[\"layer_1\"][\"fMRI_EVC\"], percentile=True, title=title_res)\n",
    "plot_rdm(layer_1, percentile=True, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fMRI EVC residual RDM\n",
    "title_res = \"Residual fMRI IT RDM\"\n",
    "title = \"fMRI IT RDM\"\n",
    "plot_rdm(resRDM_dict[\"layer_1\"][\"fMRI_IT\"], percentile=True, title=title_res)\n",
    "plot_rdm(fMRI_IT, percentile=True, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEG-fMRI comparison: To find out at which timepoint MEG representation is similar to a given ROI's representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDM Comparison functions\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def RSA_spearman(rdm1,rdm2):\n",
    "    \"\"\"\n",
    "    computes and returns the spearman correlation between lower triangular \n",
    "    part of the input rdms. We only need to compare either lower or upper \n",
    "    triangular part of the matrix as RDM is symmetric\n",
    "    \"\"\"\n",
    "    # get lower triangular part of the RDM1 \n",
    "    lt_rdm1 = get_lowertriangular(rdm1)\n",
    "    # get lower triangular part of the RDM1 \n",
    "    lt_rdm2 = get_lowertriangular(rdm2)\n",
    "    # return Spearman's correlation between lower triangular part of rdm1 & rdm2\n",
    "    return spearmanr(lt_rdm1, lt_rdm2)[0]\n",
    "\n",
    "def get_lowertriangular(rdm):\n",
    "    \"\"\"\n",
    "    returns lower triangular part of the matrix\n",
    "    \"\"\"\n",
    "    num_conditions = rdm.shape[0]\n",
    "    return rdm[np.tril_indices(num_conditions,-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlating MEG RDMs with fMRI RDMs\n",
    "num_timepoints =resRDM_dict[\"layer_1\"][\"MEG\"].shape[0] # get number of timepoints\n",
    "\n",
    "# initialize a dictionary to store MEG and ROI RDM correlation at each timepoint\n",
    "MEG_correlation = {}\n",
    "ROIs = ['EVC_1','IT_1','EVC_2','IT_2', 'EVC', 'IT']\n",
    "for ROI in ROIs:\n",
    "  MEG_correlation[ROI] = []\n",
    "\n",
    "# for loop that goes over MEG RDMs at all time points and correlate with ROI RDMs\n",
    "for t in range(num_timepoints):\n",
    "  MEG_RDM_t = resRDM_dict[\"layer_1\"][\"MEG\"][t,:,:]\n",
    "  MEG_correlation['EVC_1'].append(RSA_spearman(fMRI_EVC, MEG_RDM_t))\n",
    "  MEG_correlation['IT_1'].append(RSA_spearman(fMRI_IT, MEG_RDM_t))\n",
    "  #MEG_correlation['EVC_1'].append(RSA_spearman(resRDM_dict[\"layer_1\"]['fMRI_EVC'], MEG_RDM_t))\n",
    "  #MEG_correlation['IT_1'].append(RSA_spearman(resRDM_dict[\"layer_1\"]['fMRI_IT'], MEG_RDM_t))\n",
    "  MEG_RDM_t = resRDM_dict[\"layer_2\"][\"MEG\"][t,:,:]\n",
    "  MEG_correlation['EVC_2'].append(RSA_spearman(fMRI_EVC, MEG_RDM_t))\n",
    "  MEG_correlation['IT_2'].append(RSA_spearman(fMRI_IT, MEG_RDM_t))\n",
    "  #MEG_correlation['EVC_2'].append(RSA_spearman(resRDM_dict[\"layer_2\"]['fMRI_EVC'], MEG_RDM_t))\n",
    "  #MEG_correlation['IT_2'].append(RSA_spearman(resRDM_dict[\"layer_2\"]['fMRI_IT'], MEG_RDM_t))\n",
    "  MEG_RDM_t = MEG_RDMs[t,:,:]\n",
    "  MEG_correlation['EVC'].append(RSA_spearman(fMRI_EVC, MEG_RDM_t))\n",
    "  MEG_correlation['IT'].append(RSA_spearman(fMRI_IT, MEG_RDM_t))\n",
    "  #for ROI in ROIs:\n",
    "  #  ROI_RDM = resRDM_dict[\"layer_2\"]['fMRI_'+ ROI]\n",
    "  #  MEG_correlation[ROI].append(RSA_spearman(ROI_RDM, MEG_RDM_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting MEG-fMRI comparison\n",
    "import matplotlib.pyplot as plt\n",
    "# for Palatino and other serif fonts use:\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "})\n",
    "plt.rc('font', size=12)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "time_range = range(-100,1201)\n",
    "ax.plot(time_range, MEG_correlation['IT'], color='tab:brown', label=r'$\\rho(\\textrm{IT}, \\textrm{MEG}(t))$')\n",
    "ax.plot(time_range, MEG_correlation['IT_1'], color='tab:orange', label=r'$\\rho(\\textrm{IT}, \\textrm{MEG}(t)-\\textrm{Layer 1})$')\n",
    "\n",
    "ax.plot(time_range, MEG_correlation['IT_2'], color='tab:red', label=r'$\\rho(\\textrm{IT}, \\textrm{MEG}(t)-\\textrm{Layer 2})$')\n",
    "ax.plot(time_range, MEG_correlation['EVC'], color='tab:gray', label=r'$\\rho(\\textrm{EVC}, \\textrm{MEG}(t))$')\n",
    "ax.plot(time_range, MEG_correlation['EVC_1'], color='tab:blue', label=r'$\\rho(\\textrm{EVC}, \\textrm{MEG}(t)-\\textrm{Layer 1})$')\n",
    "ax.plot(time_range, MEG_correlation['EVC_2'], color='tab:purple', label=r'$\\rho(\\textrm{EVC}, \\textrm{MEG}(t)-\\textrm{Layer 2})$')\n",
    "\n",
    "# Same as above\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Spearmans Correlation')\n",
    "ax.set_title('MEG-fMRI fusion')\n",
    "ax.grid(True)\n",
    "ax.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RSA import RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = np.shape(fMRI_IT)\n",
    "similarities = RSA(fMRI_IT, MEG_RDMs[100:400], permutation=True, n_iter=10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Regression3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
